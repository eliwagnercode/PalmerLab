{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration\n",
        "- Counting null values in each column and dropping the six columns containing only null values decreased the proportion of nulls in the dataset from 21.1% to 13.6%.\n",
        "\n",
        "- Explanations for null values may lie in exploring differences between cohorts, sex, or behavioral environments.\n",
        "\n",
        "- Males and females contributed similarly to total null values; sex does not seem to be the best avenue to pursue at first glance.\n",
        "\n",
        "- Cohorts 16 and 17 differ from other cohorts in that they each contribute to more than 10% of total null values in the dataset. However, further comparing against the proportion of total animals reveals that cohorts 4 and 16 contribute 1.6 null values per capita, and cohorts 2 and 17 contribute 1.5 null values per capita.\n",
        "\n",
        "- Similarly, room BSB273B contributes to 23.6% of total null values in the dataset, but it also was used to run 23.5% of all animals in the dataset, so it only contributes to 1.0 null values per capita.\n",
        "\n",
        "- The top three rooms by null values per capita ran too few animals to draw meaningful conclusions; excluding these, only room MTF134B had a higher null count per capita than BSB273B. Comparing room number against cohort number reveals that 75% of cohort 16 was run in BSB273B, while 100% of cohort 17 was run in MTF134B. The computers in these rooms may have had issues exporting data from Med Associates software because of how the MPC2XL export template was written, or they may have been using MedState Notation programs that were not written to record all the same variables recorded on other computers.\n",
        "\n",
        "- Condensing the dataset to the most utile columns and re-inspecting null values added some support to exploring cohort and room differences. For the remaining dataset, columns relating to aggressive/defensive behavior counts contributes to approximately 33% of all null values.\n",
        "\n",
        "- An easy first step to exploring this further would be confirming which animals were excluded from the aggressive/defensive behavior count aspect of the project, and why. If the number of animals excluded does not correlate with the spread of null values, there may be another issue at play for the missing data."
      ],
      "metadata": {
        "id": "qVlucfVZtrTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Load CSV into Pandas DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df_phenotypes = pd.read_csv('https://raw.githubusercontent.com/eliwagnercode/PalmerLab/main/phenotype_data_edited.csv')\n",
        "df_phenotypes"
      ],
      "metadata": {
        "id": "cVSJq5Vx3kST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # DRY functions to count nulls\n",
        "\n",
        "def get_nullsByCol(df):\n",
        "  colNulls = df.isna().sum()\n",
        "  df_colNulls = colNulls.to_frame(name='n_nulls')\\\n",
        "    .rename_axis('column_name')\\\n",
        "    .sort_values('n_nulls',ascending=False)\n",
        "  print('Total null count in DataFrame: ',df_phenotypes.isna().sum().sum())\n",
        "  print('Percent null in DataFrame: ',\n",
        "      round(100*df.isna().sum().sum()\\\n",
        "      /(df.shape[0]*df.shape[1]),1))\n",
        "  return df_colNulls\n",
        "\n",
        "# This function would be more efficient using only numpy arrays, but \n",
        "# it works well for a dataset with fewer than 1000 rows.\n",
        "def get_nullsByGroup(df,column_name_str):\n",
        "  df['n_nulls'] = df.isna().sum(axis=1)\n",
        "  df_valueCounts = df.value_counts(column_name_str)\\\n",
        "    .to_frame(name='n_animals')\\\n",
        "    .rename_axis(column_name_str)\\\n",
        "    .reset_index()\n",
        "\n",
        "  df_valueCounts['total_values'] = df_valueCounts['n_animals']\\\n",
        "    * df.shape[1]\n",
        "\n",
        "  df_nulls = df.groupby(column_name_str)['n_nulls'].sum()\\\n",
        "    .to_frame(name='n_nulls')\\\n",
        "    .rename_axis(column_name_str)\\\n",
        "    .reset_index()\n",
        "    \n",
        "  df_nulls = df_nulls.merge(\n",
        "      df_valueCounts,on=column_name_str)\n",
        "\n",
        "  percent_group_values = []\n",
        "  percent_all_animals = []\n",
        "  percent_all_nulls = []\n",
        "  nulls_per_capita = []\n",
        "  n_animals = df_nulls['n_animals'].to_list()\n",
        "  nulls = df_nulls['n_nulls'].to_list()\n",
        "  totals = df_nulls['total_values'].to_list()\n",
        "  for null_count, animal_count, total_count in zip(nulls,n_animals,totals):\n",
        "    pct_grp_val = round(100*null_count/total_count,1)\n",
        "    pct_animals = round(100*animal_count/len(df),1)\n",
        "    pct_nulls = round(100*null_count/df.copy().isna().sum().sum(),1)\n",
        "    nulls_per_cap = round(pct_nulls/pct_animals,1)\n",
        "    percent_group_values.append(pct_grp_val)\n",
        "    percent_all_animals.append(pct_animals)\n",
        "    percent_all_nulls.append(pct_nulls)\n",
        "    nulls_per_capita.append(nulls_per_cap)\n",
        "\n",
        "  df_nulls['percent_group_values'] = percent_group_values\n",
        "  df_nulls['percent_all_animals'] = percent_all_animals\n",
        "  df_nulls['percent_all_nulls'] = percent_all_nulls\n",
        "  df_nulls['nulls_per_capita'] = nulls_per_capita\n",
        "\n",
        "  df_nulls = df_nulls[[column_name_str,\n",
        "                       'n_animals',\n",
        "                       'percent_all_animals',\n",
        "                       'n_nulls',\n",
        "                       'percent_group_values',\n",
        "                       'percent_all_nulls',\n",
        "                       'nulls_per_capita'\n",
        "                       ]]\n",
        "\n",
        "  df_nulls = df_nulls.sort_values(by='percent_group_values',ascending=False)\n",
        "  return df_nulls"
      ],
      "metadata": {
        "id": "5AoPL-LX16aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count nulls by column\n",
        "df = get_nullsByCol(df_phenotypes)\n",
        "df[:10]"
      ],
      "metadata": {
        "id": "Hl00_lcqbtVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Drop null-only columns from DataFrame and count nulls by column\n",
        "colNullsAll = df.loc[\n",
        "    df['n_nulls'] == len(df_phenotypes)\n",
        "    ].index.to_list()\n",
        "df_phenotypes = df_phenotypes.copy().drop(\n",
        "    columns=colNullsAll)\n",
        "df = get_nullsByCol(df_phenotypes)\n",
        "df[:10]"
      ],
      "metadata": {
        "id": "6BF4dH5T9SKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count nulls by cohort\n",
        "df_cohort = get_nullsByGroup(df_phenotypes,'cohort')\n",
        "df_cohort"
      ],
      "metadata": {
        "id": "pO8zu8EUC6bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count nulls by sex\n",
        "df_sex = get_nullsByGroup(df_phenotypes,'sex')\n",
        "df_sex"
      ],
      "metadata": {
        "id": "1Xz1TZDcCoL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count nulls by behavior room\n",
        "df_room = get_nullsByGroup(df_phenotypes,'room')\n",
        "df_room"
      ],
      "metadata": {
        "id": "m4VxjApJCo5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count animals by cohort run in room BSB273B\n",
        "df_phenotypes[['rfid','cohort','room','box']].loc[(df_phenotypes['room']=='BSB273B')].value_counts('cohort')"
      ],
      "metadata": {
        "id": "Gnz5wy2-0QX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count animals by cohort run in room MTF134B\n",
        "df_phenotypes[['rfid','cohort','room','box']].loc[(df_phenotypes['room']=='MTF134B')].value_counts('cohort')"
      ],
      "metadata": {
        "id": "-bx4FhK48diB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count nulls by behavior room and operant chamber\n",
        "df_phenotypes['room_box'] = df_phenotypes['room'].astype(str) + '_' + df_phenotypes['box'].astype(str)\n",
        "df_room_box = get_nullsByGroup(df_phenotypes,'room_box')\n",
        "df_phenotypes = df_phenotypes.drop(columns='room_box')\n",
        "df_room_box"
      ],
      "metadata": {
        "id": "ctd1moSHs8aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Combine and drop columns\n",
        "df_phenotypes['sha_mean_total_presses_08_10'] = df_phenotypes[['sha_mean_08_10', 'sha_mean_inactive_08_10',\n",
        "       'sha_mean_to_08_10']].sum(axis=1)\n",
        "df_phenotypes['sha_mean_total_presses_01_03'] = df_phenotypes[['sha_mean_01_03', 'sha_mean_inactive_01_03',\n",
        "       'sha_mean_to_01_03']].sum(axis=1)\n",
        "df_phenotypes = df_phenotypes[[\n",
        "    'cohort', 'rfid', 'sex', 'room','box',\n",
        "    'irr_age','lga_12_age','pr_01_age','pr_02_age','pr_03_age','sha_01_age','sha_08_age','shock_03_age',\n",
        "    'sha_mean_01_03','sha_mean_total_presses_01_03','sha_mean_08_10','sha_mean_total_presses_08_10','sha_behavior_stability_08_10', 'sha_behavior_stability_08_10_na','sha_coefficient_of_variation', 'sha_coefficient_of_variation_2',\n",
        "    'lga_mean_12_14','lga_behavior_stability_12_14', 'lga_behavior_stability_12_14_na','lga_coefficient_of_variation', \n",
        "    'shock_03', 'shock_03_pre', 'shock_03_avg1h', \n",
        "    'pr_01_sha_breakpoint', 'pr_02_lga_breakpoint','pr_03_postshock_breakpoint', 'pr_max_02_03_breakpoint',\n",
        "    'irr_agg_change', 'irr_def_change', 'irr_total_change',\n",
        "    'addiction_index_no_sex_z','add_index_sexcohort_z', 'add_ind_calc_no_z_shock_03','addiction_index_no_sex_z_shock_03_avg1h','add_index_palmer_shock_03_avg1h', 'add_ind_calc_no_z_shock_03_avg1h','add_ind_olivier'\n",
        "]]"
      ],
      "metadata": {
        "id": "Efh81CIHJoa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count nulls by cohort\n",
        "df_cohort = get_nullsByGroup(df_phenotypes,'cohort')\n",
        "df_cohort"
      ],
      "metadata": {
        "id": "sSS21UjLNi28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count null by sex\n",
        "df_sex = get_nullsByGroup(df_phenotypes,'sex')\n",
        "df_sex"
      ],
      "metadata": {
        "id": "iG8Jhn2BNqhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count null by behavior room\n",
        "df_room = get_nullsByGroup(df_phenotypes,'room')\n",
        "df_room"
      ],
      "metadata": {
        "id": "AovFPOsuN6qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Count null by behavior room and operant chamber\n",
        "df_phenotypes['room_box'] = df_phenotypes['room'].astype(str) + '-' + df_phenotypes['box'].astype(str)\n",
        "df_room_box = get_nullsByGroup(df_phenotypes,'room_box')\n",
        "df_phenotypes = df_phenotypes.drop(columns='room_box')\n",
        "df_room_box"
      ],
      "metadata": {
        "id": "reH41D6ZP0zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_phenotypes.loc[df_phenotypes['room']=='BSB273B']\n",
        "get_nullsByCol(df)"
      ],
      "metadata": {
        "id": "1y8taDEXV9P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stats\n",
        "\n",
        "- Because there are so many missing values for traits relating to aggressive/defensive behavior, I decided to only explore self-administration for this assignment.\n",
        "\n",
        "- Because there are no clearly indicated group differences with respect to genotype, treatment, or training context, the only obvious parameters to run group comparisons for behavioral data are sex and age.\n",
        "\n",
        "- Given more time for the assignment I might classify animals into age brackets and run two-way ANOVA for different traits against age and sex. Because the maximum age for what is seemingly the last experiment in the project, pr_03_age, is only 143 days, and because there is no indication from the dataset that this strain of animal is a model of age-related disorders, I decided to focus only on exploring sex differences for ShA.\n",
        "\n",
        "- Outliers were defined as those with values further than 1.5x the IQR away from the first or third quartile. Outliers were only removed before grouping by sex. Upon inspecting within groups, it was revealed that the male group appeared to have a much more condensed spread with more outliers compared to the female group.\n",
        "\n",
        "- Although the two groups had a different spread, a t-test was not strong enough to reject the null hypothesis."
      ],
      "metadata": {
        "id": "E3PSApkGi3Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_phenotypes.loc[df_phenotypes['isMale']==0]['sha_mean_08_10'].describe())"
      ],
      "metadata": {
        "id": "F0vKQ7G0YHrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_phenotypes.loc[df_phenotypes['isMale']==1]['sha_mean_08_10'].describe()"
      ],
      "metadata": {
        "id": "_oODJMpGfIfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_phenotypes = df_phenotypes.drop(columns=['irr_age', 'lga_12_age',\n",
        "       'pr_01_age', 'pr_02_age', 'pr_03_age', 'sha_01_age', 'sha_08_age',\n",
        "       'shock_03_age','irr_agg_change', 'irr_def_change', 'irr_total_change',])"
      ],
      "metadata": {
        "id": "sf8OgERme1As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Encode sex column with numeric value\n",
        "encode_sex = []\n",
        "for sex in df_phenotypes['sex'].to_list():\n",
        "  if sex == 'F':\n",
        "    encode_sex.append(0)\n",
        "  else:\n",
        "    encode_sex.append(1)\n",
        "df_phenotypes['isMale'] = encode_sex\n",
        "df_phenotypes = df_phenotypes.drop(columns='sex')\n",
        "df_phenotypes"
      ],
      "metadata": {
        "id": "NyTa14OdYdgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inspect ShA for outliers\n",
        "import seaborn as sns\n",
        "print(df_phenotypes.loc[df_phenotypes['isMale']==0]['sha_mean_08_10'].describe())\n",
        "sns.boxplot(df_phenotypes['sha_mean_08_10'])"
      ],
      "metadata": {
        "id": "DbAKM2azcJVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove outliers by interquartile range approach\n",
        "Q1 = df_phenotypes['sha_mean_08_10'].quantile(0.25)\n",
        "Q3 = df_phenotypes['sha_mean_08_10'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower = Q1 - 1.5*IQR\n",
        "upper = Q3 + 1.5*IQR\n",
        "df_phenotypes = df_phenotypes.loc[\n",
        "    (df_phenotypes['sha_mean_08_10']<=upper)\n",
        "    & (df_phenotypes['sha_mean_08_10']>=lower)]"
      ],
      "metadata": {
        "id": "shVwEZ1lSf3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Divide DataFrame by sex\n",
        "males = df_phenotypes.loc[df_phenotypes['isMale']==1].reset_index(drop=True)\n",
        "females = df_phenotypes.loc[df_phenotypes['isMale']==0].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "DSfPxmGxg80W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inspect male ShA responding\n",
        "print(males['sha_mean_08_10'].describe())\n",
        "sns.boxplot(males['sha_mean_08_10'])"
      ],
      "metadata": {
        "id": "Fo7l6oHyhQSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inspect female ShA responding\n",
        "print(females['sha_mean_08_10'].describe())\n",
        "sns.boxplot(females['sha_mean_08_10'])"
      ],
      "metadata": {
        "id": "Jb5H-yUrRClF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title t-test\n",
        "from scipy.stats import ttest_ind\n",
        "ttest_ind(males['sha_mean_08_10'],females['sha_mean_08_10'])"
      ],
      "metadata": {
        "id": "1MSzVcM_bSRr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}